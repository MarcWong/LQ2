{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file analyzes the crowdsourcing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import toolz\n",
    "import glob as glob\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the url anonymous \n",
    "def makeUrlAnonymous(url):\n",
    "    return 'https://anonymouslink/folder/' + url.split('/')[-1]\n",
    "\n",
    "for batchResultsFile in glob.glob(os.path.join('MTurkData', '*batch_results.csv')):\n",
    "    batchResultsFileDf = pd.read_csv(batchResultsFile)\n",
    "    \n",
    "    for idx in range(1,11):\n",
    "        try:\n",
    "            batchResultsFileDf['Input.img' + str(idx) + '_1'] = batchResultsFileDf['Input.img' + str(idx) + '_1'].apply(lambda x: makeUrlAnonymous(x))\n",
    "            batchResultsFileDf['Input.img' + str(idx) + '_2'] = batchResultsFileDf['Input.img' + str(idx) + '_2'].apply(lambda x: makeUrlAnonymous(x))\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    batchResultsFileDf.to_csv(batchResultsFile, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = pd.concat([pd.read_csv('MTurkData/exp1_e1_batch_results.csv'),\n",
    "                     pd.read_csv('MTurkData/exp1_e2_batch_results.csv'),\n",
    "                     pd.read_csv('MTurkData/exp1_e3_batch_results.csv')])\n",
    "exp2 = pd.concat([pd.read_csv('MTurkData/exp2_e1_batch_results.csv'),\n",
    "                     pd.read_csv('MTurkData/exp2_e2_batch_results.csv'),\n",
    "                     pd.read_csv('MTurkData/exp2_e3_batch_results.csv')])\n",
    "expAll = pd.concat([exp1, exp2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participants in Exp 1:  280\n",
      "Participants in Exp 2:  176\n",
      "Total:  416\n"
     ]
    }
   ],
   "source": [
    "print('Participants in Exp 1: ', exp1['WorkerId'].nunique())\n",
    "print('Participants in Exp 2: ', exp2['WorkerId'].nunique())\n",
    "print('Total: ', expAll['WorkerId'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1726\n",
       "False     752\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## There is one duplicate question per HIT. The HIT will be rejected if the answers are not consistent\n",
    "def getQuality(row):\n",
    "    ans = json.loads(row['Answer.taskAnswers'])[0]\n",
    "    if (ans['img10_1']['img10_1'] == ans['img1_1']['img1_1']):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "expAll['quality'] = expAll.apply(lambda x: getQuality(x), axis = 1) \n",
    "expAll.quality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1726, 49)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Keep only the valid ones\n",
    "resultDf = expAll[expAll.quality == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15534, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Unpack the responses into paired results\n",
    "pairs = []\n",
    "answers = []\n",
    "for idx, row in resultDf.iterrows():\n",
    "    ans = json.loads(row['Answer.taskAnswers'])[0]\n",
    "    for i in range(1, 9 + 1):\n",
    "        key = 'img' + str(i) + '_1'\n",
    "        key2 = 'img' + str(i) + '_2'\n",
    "        \n",
    "        if ans[key][key] == True:\n",
    "            pairs.append([row[\"Input.\" + key], row[\"Input.\" + key2], 1])\n",
    "        else:\n",
    "            pairs.append([row[\"Input.\" + key], row[\"Input.\" + key2], 2])\n",
    "            \n",
    "pairDf = pd.DataFrame(pairs, columns=['img1', 'img2', 'wIdx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15500, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairDf.dropna(inplace = True)\n",
    "pairDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the winning counts per pair\n",
    "pairDf['cIdx'] = pairDf['img1'].apply(lambda x: x.split('/')[-1].split('_')[0])\n",
    "pairCountDf = pairDf.groupby(['img1', 'img2', 'wIdx']).size().unstack().fillna(0)\n",
    "pairCountDf = pairCountDf.reset_index()\n",
    "pairCountDf['cIdx'] = pairCountDf['img1'].apply(lambda x: x.split('/')[-1].split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5343, 9)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, row in pairCountDf.iterrows():\n",
    "    if row[1] > row[2]:\n",
    "        pairCountDf.loc[idx, 'good'] = row['img1']\n",
    "        pairCountDf.loc[idx, 'bad'] = row['img2']\n",
    "        pairCountDf.loc[idx, 'goodCount'] = row[1]\n",
    "        pairCountDf.loc[idx, 'badCount'] = row[2]\n",
    "    elif row[1] < row[2]:\n",
    "        pairCountDf.loc[idx, 'good'] = row['img2']\n",
    "        pairCountDf.loc[idx, 'bad'] = row['img1']\n",
    "        pairCountDf.loc[idx, 'goodCount'] = row[2]\n",
    "        pairCountDf.loc[idx, 'badCount'] = row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total aggrement:  0.4555182543013009\n"
     ]
    }
   ],
   "source": [
    "finaldf = pairCountDf[['img1', 'img2', 'good', 'bad', 'cIdx', 'goodCount', 'badCount']].reset_index(drop=True)\n",
    "finaldf.reset_index(drop=True,  inplace=True)\n",
    "finaldf.dropna(inplace = True)\n",
    "agreedf = finaldf[finaldf.apply(lambda x: x['badCount'] == 0, axis=1)]\n",
    "print('Total aggrement: ', agreedf.shape[0] / finaldf.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
