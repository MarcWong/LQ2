{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Variable\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_new_dataset, load_dataset, maxvalue, minvalue\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_arg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelArg\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m correct\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bs4\n",
    "import pickle as pkl\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "import os\n",
    "import math\n",
    "import random \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from utils.loader import load_new_dataset, load_dataset, maxvalue, minvalue\n",
    "from utils.model_arg import ModelArg\n",
    "from utils.evaluate import correct\n",
    "from utils.selection import getModel\n",
    "from utils.plot_res import plotpkl, plot\n",
    "from utils.test import _get_single_block, get_score_correct\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Neccessary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /netpool/homes/wangyo/.conda/envs/blenderproc/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/netpool/homes/wangyo/Projects/LQ2/src/baseline/parse_feature_from_vega.py:93: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if len(transforms) is 1:  # safe like y & normal x\n",
      "Traceback (most recent call last):\n",
      "  File \"/netpool/homes/wangyo/Projects/LQ2/src/baseline/parse_feature_from_vega.py\", line 8, in <module>\n",
      "    from altair_saver import save\n",
      "ModuleNotFoundError: No module named 'altair_saver'\n"
     ]
    }
   ],
   "source": [
    "! python parse_feature_from_vega.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /netpool/homes/wangyo/.conda/envs/blenderproc/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Traceback (most recent call last):\n",
      "  File \"/netpool/homes/wangyo/Projects/LQ2/src/baseline/generate_empirical_score.py\", line 275, in <module>\n",
      "    calculate_measures('../dataset/exp1/graphical_features', '../dataset/exp1/metrics.csv')\n",
      "  File \"/netpool/homes/wangyo/Projects/LQ2/src/baseline/generate_empirical_score.py\", line 262, in calculate_measures\n",
      "    with open(filename, 'rb') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '../dataset/exp1/graphical_features'\n"
     ]
    }
   ],
   "source": [
    "! python generate_empirical_score.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand-Crafted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_ids = ['whiteSpaceArea', 'graphicSpread', 'graphicDistance','graphicSize', 'graphicSizeVar', 'graphicSizeMin','groupSizeVar', 'groupDistanceMin', 'graphicXSymmetry', 'graphicXAsymmetry', 'graphicYSymmetry', 'graphicYAsymmetry', 'textXsymmetry', 'textXAsymmetry', 'textYsymmetry','textYAsymmetry']\n",
    "weights  = [0.2, 50, 50, 50, 50, 125, 2.5, 250, 50, 0.2, 50, 0.2, 50, 0.2, 50, 0.2]\n",
    "groups = [[0,1,2], [3,4,5], [6,7], [8,9,10,11,12,13,14,15], list(range(0, 16))]\n",
    "group_names = ['White Space', 'Scale', 'Unity', 'Balance', 'All']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pairwise(X, y):\n",
    "    \"\"\"Transforms data into pairs with balanced labels for ranking\n",
    "    Transforms a n-class ranking problem into a two-class classification\n",
    "    problem. Subclasses implementing particular strategies for choosing\n",
    "    pairs should override this method.\n",
    "    In this method, all pairs are choosen, except for those that have the\n",
    "    same target value. The output is an array of balanced classes, i.e.\n",
    "    there are the same number of -1 as +1\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape (n_samples, n_features)\n",
    "        The data\n",
    "    y : array, shape (n_samples,) or (n_samples, 2)\n",
    "        Target labels. If it's a 2D array, the second column represents\n",
    "        the grouping of samples, i.e., samples with different groups will\n",
    "        not be considered.\n",
    "    Returns\n",
    "    -------\n",
    "    X_trans : array, shape (k, n_feaures)\n",
    "        Data as pairs\n",
    "    y_trans : array, shape (k,)\n",
    "        Output class labels, where classes have values {-1, +1}\n",
    "    \"\"\"\n",
    "    X_new = []\n",
    "    y_new = []\n",
    "    y = np.asarray(y)\n",
    "    if y.ndim == 1:\n",
    "        y = np.c_[y, np.ones(y.shape[0])]\n",
    "    comb = itertools.combinations(range(X.shape[0]), 2)\n",
    "    for k, (i, j) in enumerate(comb):\n",
    "        if y[i, 0] == y[j, 0] or y[i, 1] != y[j, 1]:\n",
    "            # skip if same target or different group\n",
    "            continue\n",
    "        X_new.append(X[i] - X[j])\n",
    "        y_new.append(np.sign(y[i, 0] - y[j, 0]))\n",
    "        # output balanced classes\n",
    "        if y_new[-1] != (-1) ** k:\n",
    "            y_new[-1] = - y_new[-1]\n",
    "            X_new[-1] = - X_new[-1]\n",
    "    return np.asarray(X_new), np.asarray(y_new).ravel()\n",
    "\n",
    "\n",
    "class RankSVM(SGDClassifier):\n",
    "    \"\"\"Performs pairwise ranking with an underlying SGDClassifer model\n",
    "    Input should be a n-class ranking problem, this object will convert it\n",
    "    into a two-class classification problem, a setting known as\n",
    "    `pairwise ranking`.\n",
    "    Authors: Fabian Pedregosa <fabian@fseoane.net>\n",
    "             Alexandre Gramfort <alexandre.gramfort@inria.fr>\n",
    "    https://gist.github.com/2071994\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit a pairwise ranking model.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape (n_samples, n_features)\n",
    "        y : array, shape (n_samples,) or (n_samples, 2)\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        X_trans, y_trans = transform_pairwise(X, y)\n",
    "        super(RankSVM, self).fit(X_trans, y_trans)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = super(RankSVM, self).predict(X)\n",
    "        # preds are mapped to {-1,1}\n",
    "        # FIXME only works in this example!!!\n",
    "        pred[pred == -1] = 0\n",
    "        return pred\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Because we transformed into a pairwise problem, chance level is at 0.5\n",
    "        \"\"\"\n",
    "        X_trans, y_trans = transform_pairwise(X, y)\n",
    "        return np.mean(super(RankSVM, self).predict(X_trans) == y_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Space\n",
      "['whiteSpaceArea', 'graphicSpread', 'graphicDistance']\n",
      "SGDClassifier(alpha=0.01, max_iter=100)    0.554608\n",
      "RankSVM()                                  0.572355\n",
      "RankSVM(alpha=0.1)                         0.576109\n",
      "dtype: float64\n",
      "-------------------------\n",
      "Scale\n",
      "['graphicSize', 'graphicSizeVar', 'graphicSizeMin']\n",
      "SGDClassifier(alpha=0.01, max_iter=100)    0.575768\n",
      "RankSVM()                                  0.583276\n",
      "RankSVM(alpha=0.1)                         0.571331\n",
      "dtype: float64\n",
      "-------------------------\n",
      "Unity\n",
      "['groupSizeVar', 'groupDistanceMin']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haha/LQ2/venv/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:573: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.01, max_iter=100)    0.506826\n",
      "RankSVM()                                  0.500341\n",
      "RankSVM(alpha=0.1)                         0.517747\n",
      "dtype: float64\n",
      "-------------------------\n",
      "Balance\n",
      "['graphicXSymmetry', 'graphicXAsymmetry', 'graphicYSymmetry', 'graphicYAsymmetry', 'textXsymmetry', 'textXAsymmetry', 'textYsymmetry', 'textYAsymmetry']\n",
      "SGDClassifier(alpha=0.01, max_iter=100)    0.568942\n",
      "RankSVM()                                  0.584642\n",
      "RankSVM(alpha=0.1)                         0.568942\n",
      "dtype: float64\n",
      "-------------------------\n",
      "All\n",
      "['whiteSpaceArea', 'graphicSpread', 'graphicDistance', 'graphicSize', 'graphicSizeVar', 'graphicSizeMin', 'groupSizeVar', 'groupDistanceMin', 'graphicXSymmetry', 'graphicXAsymmetry', 'graphicYSymmetry', 'graphicYAsymmetry', 'textXsymmetry', 'textXAsymmetry', 'textYsymmetry', 'textYAsymmetry']\n",
      "SGDClassifier(alpha=0.01, max_iter=100)    0.513311\n",
      "RankSVM()                                  0.556314\n",
      "RankSVM(alpha=0.1)                         0.592150\n",
      "dtype: float64\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "exp = 'exp1'\n",
    "if exp == 'exp1':\n",
    "    metricsDf = pd.read_csv('../dataset/exp1/metrics.csv')\n",
    "    labelDf = pd.read_csv('../dataset/exp1/turk_results.csv')\n",
    "else:\n",
    "    metricsDf = pd.read_csv('../dataset/exp2/metrics.csv')\n",
    "    labelDf = pd.read_csv('../dataset/exp2/turk_results.csv')\n",
    "\n",
    "labelDf['goodName'] = labelDf['good'].apply(lambda x: x.split('/')[-1].split('.')[0])\n",
    "labelDf['badName'] = labelDf['bad'].apply(lambda x: x.split('/')[-1].split('.')[0])\n",
    "labelDf.head()\n",
    "\n",
    "goodPara = metricsDf.merge(labelDf, left_on='name', right_on = 'goodName')\n",
    "badPara = metricsDf.merge(labelDf, left_on='name', right_on = 'badName')\n",
    "\n",
    "for idx, group in enumerate(group_names):\n",
    "    print(group)\n",
    "    metricsInThisGroup = [metric_ids[i] for i in groups[idx]]\n",
    "    print(metricsInThisGroup)\n",
    "\n",
    "    winnerPara = goodPara[metricsInThisGroup]\n",
    "    loserPara = badPara[metricsInThisGroup]\n",
    "    winnerPara.head()\n",
    "\n",
    "    differences = (winnerPara - loserPara).fillna(0).values\n",
    "\n",
    "    Y = []\n",
    "    X = differences.copy()\n",
    "    for idx, d in enumerate(X):\n",
    "        if idx % 2:\n",
    "            Y.append(0)\n",
    "            X[idx] = -d\n",
    "        else:\n",
    "            Y.append(1)\n",
    "\n",
    "    testAccs = []\n",
    "    for MCVDidx in range(0,10):\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, \\\n",
    "                                                            random_state=random.randint(1,10000))\n",
    "\n",
    "        Accs = []\n",
    "        Names = []\n",
    "        for clf, name in ((SGDClassifier(max_iter=100, alpha=0.01), \"plain sgd\"),\n",
    "                        (RankSVM(alpha=0.0001, tol=1e-3, loss='hinge'), 'RankSVM'),\n",
    "        #                   (SGDClassifier(max_iter=1000, alpha=0.01,\n",
    "        #                                  loss='roc_pairwise_ranking'), \"pairwise sgd\"),\n",
    "                          (RankSVM(alpha=0.1, loss='hinge'), 'RankSVM'),\n",
    "                          ):\n",
    "            clf.fit(X_train, Y_train)\n",
    "\n",
    "            pred = clf.predict(X_test)\n",
    "            Accs.append(metrics.accuracy_score(Y_test, pred))\n",
    "            Names.append(clf)\n",
    "\n",
    "        testAccs.append(Accs)\n",
    "\n",
    "    print(pd.DataFrame(testAccs, columns=Names).mean())\n",
    "    print(\"-------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size=1133 split=226 train_indices=907 val_indices=226\n",
      "SGDClassifier(alpha=0.01, max_iter=100)\n",
      "0.6265356265356266\n",
      "RankSVM()\n",
      "0.6265356265356266\n",
      "RankSVM(alpha=0.1)\n",
      "0.6167076167076168\n"
     ]
    }
   ],
   "source": [
    "args = ModelArg(\n",
    "    batch_size=500,\n",
    "    need_seq=False,\n",
    "    need_param=True,\n",
    "    hybrid_linearlist=[64, 256, 128, 64, 32, 16, 8, 4],\n",
    "    need_img=False,\n",
    "    h=100,\n",
    "    w=300,\n",
    "    val_split_ratio=0.2,\n",
    "    weights=[1]*6,    #[1,1,1],\n",
    "    img_path='../dataset/exp2/img',\n",
    "    label_path='../dataset/exp2/turk_results.csv',\n",
    "    param_path='../dataset/exp2/parameters.csv'\n",
    ")\n",
    "seed = random.randint(1, 10000)     \n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "train_loader, val_loader = load_new_dataset(args, device)\n",
    "\n",
    "for batch in train_loader:\n",
    "    features, groundTruth, _, _ = batch\n",
    "    gp0param = features[0][1]\n",
    "    gp1param = features[1][1]\n",
    "    gp1, gp2 = groundTruth\n",
    "    \n",
    "winnerPara = gp0param.cpu().detach().numpy()\n",
    "loserPara = gp1param.cpu().detach().numpy()\n",
    "\n",
    "differences = winnerPara - loserPara\n",
    "\n",
    "Y = []\n",
    "X = differences.copy()\n",
    "for idx, d in enumerate(X):\n",
    "    if idx % 2:\n",
    "        Y.append(0)\n",
    "        X[idx] = -d\n",
    "    else:\n",
    "        Y.append(1)\n",
    "        \n",
    "for clf, name in ((SGDClassifier(max_iter=100, alpha=0.01), \"plain sgd\"),\n",
    "                (RankSVM(alpha=0.0001, tol=1e-3), 'RankSVM'),\n",
    "#                   (SGDClassifier(max_iter=1000, alpha=0.01,\n",
    "#                                  loss='roc_pairwise_ranking'), \"pairwise sgd\"),\n",
    "                  (RankSVM(max_iter=1000, alpha=0.1, loss='hinge'), 'RankSVM'),\n",
    "                  ):\n",
    "    clf.fit(X, Y)\n",
    "    print(clf)\n",
    "    pred = clf.predict(X)\n",
    "\n",
    "#     print(metrics.f1_score(Y, pred))\n",
    "    print(metrics.accuracy_score(Y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
